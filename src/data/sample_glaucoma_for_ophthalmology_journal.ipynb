{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b66b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383d5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import random\n",
    "import sys \n",
    "import csv\n",
    "import pandas as pd\n",
    "import bz2\n",
    "from bz2 import BZ2File\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c2c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def select_samples(arr, indices):\n",
    "    ret = []\n",
    "    for i in indices:\n",
    "        ret.append(arr[i])\n",
    "    return ret\n",
    "\n",
    "def convert_to_datetime(time_str):\n",
    "    if len(time_str) != 10:\n",
    "        time_str = '0'*(10-len(time_str))+time_str\n",
    "    date_time = datetime.strptime(time_str, '%y%m%d%H%M%S')\n",
    "    return date_time\n",
    "\n",
    "def nearst_match(target, candidate_mds):\n",
    "    curr_diff = float('inf')\n",
    "    for curr in candidate_mds:\n",
    "        timestr = curr[1].strip()\n",
    "        if len(target) != 10:\n",
    "            target = '0'*(10-len(target))+target\n",
    "        if len(timestr) != 10:\n",
    "            timestr = '0'*(10-len(timestr))+timestr\n",
    "        \n",
    "        target_time = datetime.strptime(target, '%y%m%d%H%M')\n",
    "        curr_time = datetime.strptime(timestr, '%y%m%d%H%M')\n",
    "        diff = curr_time - target_time\n",
    "        diff = abs(diff.days*24*3600+diff.seconds+diff.microseconds/1e6)\n",
    "        if diff < curr_diff:\n",
    "            curr_diff = diff\n",
    "            return_curr = curr\n",
    "    return return_curr\n",
    "\n",
    "def divide_list(list_to_divide, ratios):\n",
    "    total_elements = len(list_to_divide)\n",
    "    split_index1 = int(total_elements * ratios[0])\n",
    "    split_index2 = int(total_elements * ratios[1])\n",
    "    \n",
    "    list1 = list_to_divide[:split_index1]\n",
    "    list2 = list_to_divide[split_index1:split_index2]\n",
    "    list3 = list_to_divide[split_index2:]\n",
    "    \n",
    "    return list1, list2, list3\n",
    "\n",
    "def find_all_files(folder, str_pattern='*.npz'):\n",
    "    files = [os.path.basename(y) for x in os.walk(folder) for y in glob(os.path.join(x[0], str_pattern))]\n",
    "    return files\n",
    "\n",
    "def find_all_files_(folder, str_pattern='*.npz'):\n",
    "    files = []\n",
    "    for x in os.walk(folder):\n",
    "        for y in glob(os.path.join(x[0], str_pattern)):\n",
    "            files.append(os.path.basename(y))\n",
    "        break\n",
    "#     files = [os.path.basename(y) for x in os.walk(folder) for y in glob(os.path.join(x[0], str_pattern)) break]\n",
    "    return files\n",
    "\n",
    "def merge_dicts(input_dict):\n",
    "    merge_dict = {}\n",
    "    for x in input_dict:\n",
    "        if not merge_dict:\n",
    "            for k, v in x.items():\n",
    "                merge_dict[k] = [v]\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                merge_dict[k].append(v)\n",
    "    return merge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0288d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> seed: 3755\n"
     ]
    }
   ],
   "source": [
    "#--------------------\n",
    "# run python match_oct_vf_glaucoma.py first to generate the matching table glaucoma_xxx.csv\n",
    "#--------------------\n",
    "\n",
    "# newscanfolder = '/shared/hdds_20T/cirrus_from_dicom/scans'\n",
    "# newscanfolder_p2 = '/shared/hdds_20T/cirrus_from_dicom_part2/scans'\n",
    "newscanfolder = '/shared/hdds_20T/yl535/elzelab/cirrus_ongoing/scans'\n",
    "newscanfolder_p2 = '/shared/external_hdds/external20TB_1/cirrus_from_dicom/scans'\n",
    "\n",
    "# need to mount eris data elzelab by\n",
    "# sshfs yl535@erisxdl.partners.org:/data/elzelab ~/elzelab\n",
    "\n",
    "vffile = \"/shared/hdds_20T/yl535/elzelab/hfa_ongoing/hfa_ongoing_merged_24-2_subset_cleaned_all_in.csv\"\n",
    "newoctfile = '/shared/hdds_20T/yl535/elzelab/cirrus_ongoing/metadata_OpticDiscCube_ongoing_cleaned.csv'\n",
    "# exclude_file = '/shared/ssd_16T/yl535/project/python/datasets/crosssectional/test1000_pidmaps.npy'\n",
    "exclude_file = ''\n",
    "\n",
    "# save_folder = '/shared/ssd_16T/yl535/project/python/datasets/havo_crosssectional_new_export/crosssectional_fairness_all'\n",
    "\n",
    "selected_patient_num = -1 # 3300\n",
    "selected_patient_num_train = 2000 # 31031 #\n",
    "balanced_num = -1 # 1000\n",
    "ratio_of_patients_for_test = 0.3\n",
    "num_attr = 3\n",
    "extract_to_files = True\n",
    "identity_type = 'race'\n",
    "\n",
    "# save_folder = f'/shared/ssd_16T/yl535/project/python/datasets/harvard/glaucoma.csv'\n",
    "match_table_file = f'/shared/ssd_16T/yl535/project/python/datasets/harvard/glaucoma_June23.csv'\n",
    "save_to_folder = os.path.dirname(match_table_file)\n",
    "save_file_name = os.path.basename(match_table_file)\n",
    "\n",
    "seed = -1 # 9648 9220 for iccv Galucoma Fairness dataset # -1\n",
    "\n",
    "if seed < 0:\n",
    "    seed = int(np.random.randint(10000, size=1)[0])\n",
    "set_random_seed(seed)\n",
    "\n",
    "output_folder = f'/shared/ssd_16T/yl535/project/python/datasets/harvard/glaucoma_lancet_journal_{seed}_{selected_patient_num}'\n",
    "\n",
    "\n",
    "# samples_per_attr = [int(selected_patient_num/num_attr), int(selected_patient_num/num_attr), selected_patient_num-2*int(selected_patient_num/num_attr)]\n",
    "# samples_per_attr_test = [int(selected_patient_num_test/num_attr), int(selected_patient_num_test/num_attr), selected_patient_num_test-2*int(selected_patient_num_test/num_attr)]\n",
    "\n",
    "# dict_race = {1:'American Indian or Alaska Native', \n",
    "#                 2:'Asian', \n",
    "#                 3:'Black or African American', \n",
    "#                 4:'Hispanic or Latino', \n",
    "#                 5:'Native Hawaiian or Other Pacific Islander', \n",
    "#                 6:'Other', \n",
    "#                 7:'White or Caucasian'}\n",
    "# dict_race = {2:'Asian', \n",
    "#                 3:'Black or African American', \n",
    "#                 7:'White or Caucasian'}\n",
    "dict_race = {2: 0, \n",
    "                3: 1, \n",
    "                7: 2}\n",
    "\n",
    "log_output = os.path.join(save_to_folder, f'{save_file_name}_selected_{seed}.log')\n",
    "log_output = None\n",
    "\n",
    "print(f'====> seed: {seed}')\n",
    "\n",
    "isExist = os.path.exists(save_to_folder)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(save_to_folder)\n",
    "\n",
    "if extract_to_files:\n",
    "    isExist = os.path.exists(output_folder)\n",
    "    if not isExist:\n",
    "       # Create a new directory because it does not exist\n",
    "       os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9e44438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now process oct samples\n",
      "processing 0\n",
      "0\n",
      "processing 1000\n",
      "processing 2000\n",
      "processing 3000\n",
      "processing 4000\n",
      "processing 5000\n",
      "processing 6000\n",
      "processing 7000\n",
      "processing 8000\n",
      "processing 9000\n",
      "processing 10000\n",
      "processing 11000\n",
      "processing 12000\n",
      "processing 13000\n",
      "processing 14000\n",
      "processing 15000\n",
      "processing 16000\n",
      "processing 17000\n",
      "processing 18000\n",
      "processing 19000\n",
      "processing 20000\n",
      "processing 21000\n",
      "processing 22000\n",
      "processing 23000\n",
      "processing 24000\n",
      "processing 25000\n",
      "processing 26000\n",
      "processing 27000\n",
      "processing 28000\n",
      "processing 29000\n",
      "processing 30000\n",
      "processing 31000\n",
      "processing 32000\n",
      "processing 33000\n",
      "processing 34000\n",
      "processing 35000\n",
      "processing 36000\n",
      "processing 37000\n",
      "processing 38000\n",
      "processing 39000\n",
      "processing 40000\n",
      "processing 41000\n",
      "processing 42000\n",
      "processing 43000\n",
      "processing 44000\n",
      "processing 45000\n",
      "total # of patients: 14860, total # of match records: 45207\n"
     ]
    }
   ],
   "source": [
    "octmetanew = pd.read_csv(match_table_file, sep=',')\n",
    "# existed_paths = []\n",
    "# for octpath in octmetanew['datadir']:\n",
    "#     if os.path.exists(os.path.join(newscanfolder, octpath)):\n",
    "#         existed_paths.append(octpath)\n",
    "# octmetanew_exist = octmetanew[octmetanew['datadir'].isin(existed_paths)]\n",
    "\n",
    "print(f'now process oct samples')\n",
    "clockhours_all = []\n",
    "glaucoma_all = []\n",
    "datadir_all = []\n",
    "octpath_all = []\n",
    "md_all = []\n",
    "count = 0\n",
    "unmatched = []\n",
    "race_all = []\n",
    "male_all = []\n",
    "hispanic_all = []\n",
    "ilm_maps = {}\n",
    "rnflt_maps = {}\n",
    "rnflt_attrs = {}\n",
    "upids = []\n",
    "pid_all = []\n",
    "timeoffset_all = []\n",
    "dict_pid_data = {}\n",
    "meta_all = []\n",
    "for index, row in octmetanew.iterrows():\n",
    "    if index % 1000 == 0:\n",
    "        print(f'processing {index}')\n",
    "    pid = str(row[0])\n",
    "    male = int(row['male'])\n",
    "    signalstrength = float(row['signalstrength'])\n",
    "    righteye = str(row['righteye'])\n",
    "    timeoftest = str(row['timeoftest']).strip()\n",
    "    datadir = row['datadir']\n",
    "    race = row['race']\n",
    "    # pprint(row, log_output)\n",
    "    hisp = row['hispanic']\n",
    "    race = dict_race[int(race)]\n",
    "    hisp = int(hisp)\n",
    "    md = float(row['md'])\n",
    "    glaucoma = int(row['glaucoma'])\n",
    "    datetime_timeoftest = convert_to_datetime(timeoftest)\n",
    "    age = float(row['age'])\n",
    "    \n",
    "    # if (row['race']) != 'NA' and (not np.isnan(row['race'])):\n",
    "    #     race = int(row['race'])\n",
    "    \n",
    "    #cid = pid + '_' + righteye + '_' + male \n",
    "    cid = pid + '_' + righteye\n",
    "    octID = pid + '_' + righteye + '_' + timeoftest\n",
    "    \n",
    "    # if cid not in vfid_timetd.keys():\n",
    "    #     unmatched.append(pid)\n",
    "    #     continue\n",
    "    \n",
    "#             fundus = cv2.imread(os.path.join(octpath, datadir, 'slo.jp2'))\n",
    "    if not os.path.join(os.path.join(octpath, datadir, 'slo.jp2')):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "\n",
    "        clockhours = []\n",
    "        for i in range(1,13):\n",
    "            clock_v = float(row[f'clockhour{i}'])\n",
    "            clockhours.append(clock_v)\n",
    "        clockhours = np.array(clockhours).astype(float)\n",
    "\n",
    "        pid_all.append(pid)\n",
    "#         race_all.append(race)\n",
    "#         male_all.append(male)\n",
    "#         hispanic_all.append(hisp)\n",
    "#         glaucoma_all.append(glaucoma)\n",
    "#         md_all.append(md)\n",
    "#         datadir_all.append(datadir)\n",
    "#         timeoffset_all.append(datetime_timeoftest)\n",
    "#         clockhours_all.append(clockhours)\n",
    "        \n",
    "       \n",
    "        octpath = newscanfolder\n",
    "        if not os.path.exists(os.path.join(octpath, datadir)): \n",
    "            octpath = newscanfolder_p2\n",
    "        octpath_all.append(octpath)\n",
    "        \n",
    "        data_wrt_a_sample = [pid, race, male, hisp, glaucoma, md, datadir, octpath, datetime_timeoftest, clockhours, age, row]\n",
    "        if pid not in dict_pid_data:\n",
    "            dict_pid_data[pid] = [data_wrt_a_sample]\n",
    "        else:\n",
    "            dict_pid_data[pid].append(data_wrt_a_sample)\n",
    "            \n",
    "        # if extract_to_files:\n",
    "        #     # disc\n",
    "        #     data_disk = open(os.path.join(octpath, datadir, 'mask_disc.csv'))\n",
    "        #     img_disk = np.reshape([float(row) for row in data_disk], (200, -1))\n",
    "        #     # cup\n",
    "        #     data_cup = open(os.path.join(octpath, datadir, 'mask_cup.csv'))\n",
    "        #     img_cup = np.reshape([float(row) for row in data_cup], (200, -1))\n",
    "        #     # ilm\n",
    "        #     data_ilm2nd = open(os.path.join(octpath, datadir, 'segmentation_ilm_2nd.csv'))\n",
    "        #     img_ilm2nd = np.reshape([float(row) for row in data_ilm2nd], (200, -1))\n",
    "        #     data_ilm = open(os.path.join(octpath, datadir, 'segmentation_ilm.csv'))\n",
    "        #     img_ilm = np.reshape([float(row) for row in data_ilm], (200, -1))\n",
    "        #     # gcl\n",
    "        #     data_gcl = open(os.path.join(octpath, datadir, 'segmentation_rnfl_to_gcl.csv'))\n",
    "        #     img_gcl = np.reshape([float(row) for row in data_gcl], (200, -1))\n",
    "        #     # rnflt map\n",
    "        #     rnflt_map = (img_gcl - img_ilm2nd) * 0.00195503 * 1000 # bscanPixelspacingDepth * 1000\n",
    "        #     rnflt_map[img_disk==1] = -1\n",
    "        #     rnflt_map[img_cup==1] = -2\n",
    "        #     img_gcl = img_gcl * 0.00195503 * 1000\n",
    "        #     img_ilm = np.abs(img_ilm-np.max(img_ilm)) * 0.00195503 * 1000\n",
    "\n",
    "        #     bscans = []\n",
    "        #     for i in range(1, 201):\n",
    "        #         bscan = cv2.imread(os.path.join(octpath, datadir, f'bscan{i}.jp2'))\n",
    "        #         bscan = bscan[:,:,0]\n",
    "        #         bscan = cv2.rotate(bscan, cv2.ROTATE_90_CLOCKWISE)\n",
    "        #         bscan = cv2.resize(bscan, (200,200))\n",
    "        #         # bscan = cv2.resize(cv2.rotate(bscan, cv2.ROTATE_90_CLOCKWISE), (300,200))\n",
    "        #         bscan = np.flip(bscan, axis=1)\n",
    "        #         bscan = bscan[None,:,:]\n",
    "        #         bscans.append(bscan)\n",
    "        #     bscans = np.vstack(bscans)\n",
    "\n",
    "        #     np.savez(os.path.join(output_folder,\n",
    "        #             f\"data_{index_shuf[i]:06d}.npz\"), \n",
    "        #             rnflt=rnflt_map,\n",
    "        #             ilm=img_ilm,\n",
    "        #             oct_bscans=bscans,\n",
    "        #             clockhours=clockhours,\n",
    "        #             md=md,\n",
    "        #             race=race,\n",
    "        #             male=male,\n",
    "        #             hispanic=hisp,\n",
    "        #             glaucoma=glaucoma)\n",
    "        #             # tds=tds,\n",
    "        #             # clockhours=clockhours,\n",
    "        #             # pid=octID,\n",
    "        #             # datadir=datadir\n",
    "        \n",
    "    except Exception as e:\n",
    "        unmatched.append(pid)\n",
    "        print(e)\n",
    "\n",
    "    if index % 50000 == 0:\n",
    "        print(index)\n",
    "\n",
    "unique_pids = np.unique(pid_all)\n",
    "print(f'total # of patients: {len(unique_pids)}, total # of match records: {len(pid_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7fc16e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected samples: 14860\n"
     ]
    }
   ],
   "source": [
    "# sort samples by datetime\n",
    "selected_samples = []\n",
    "pid_all = []\n",
    "for key, samples in dict_pid_data.items():\n",
    "    if len(samples) > 1:\n",
    "        datetime_wrt_a_patient = []\n",
    "        for x in samples:\n",
    "            datetime_wrt_a_patient.append(x[8])\n",
    "        datetime_wrt_a_patient.sort()\n",
    "        selected_samples.append(samples[-1])\n",
    "    elif len(samples) == 1:\n",
    "        selected_samples.append(samples[0])\n",
    "    pid_all.append(key)\n",
    "print(f'number of selected samples: {len(selected_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "35a63938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> seed: 3502\n"
     ]
    }
   ],
   "source": [
    "selected_patient_num = 3300\n",
    "\n",
    "seed = -1 # 9648 9220 for iccv Galucoma Fairness dataset # -1\n",
    "\n",
    "if seed < 0:\n",
    "    seed = int(np.random.randint(10000, size=1)[0])\n",
    "set_random_seed(seed)\n",
    "\n",
    "output_folder = f'/shared/ssd_16T/yl535/project/python/datasets/harvard/glaucoma_lancet_journal_{seed}_{selected_patient_num}'\n",
    "\n",
    "log_output = os.path.join(save_to_folder, f'{save_file_name}_selected_{seed}.log')\n",
    "log_output = None\n",
    "\n",
    "print(f'====> seed: {seed}')\n",
    "\n",
    "if extract_to_files:\n",
    "    isExist = os.path.exists(output_folder)\n",
    "    if not isExist:\n",
    "       # Create a new directory because it does not exist\n",
    "       os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c1063903",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0\n",
      "processing 1000\n",
      "processing 2000\n",
      "processing 3000\n",
      "processing 4000\n",
      "processing 5000\n",
      "processing 6000\n",
      "processing 7000\n",
      "processing 8000\n",
      "processing 9000\n",
      "processing 10000\n",
      "processing 11000\n",
      "processing 12000\n",
      "processing 13000\n",
      "processing 14000\n"
     ]
    }
   ],
   "source": [
    "race_all_new = []\n",
    "male_all_new = []\n",
    "hispanic_all_new = []\n",
    "age_all_new = []\n",
    "clockhours_all_new = []\n",
    "glaucoma_all_new = []\n",
    "pid_all_new = []\n",
    "meta_all = []\n",
    "index_shuf = list(range(len(selected_samples)))\n",
    "random.shuffle(index_shuf)\n",
    "count = 0\n",
    "for i in range(len(index_shuf)):\n",
    "    if selected_patient_num > 0 and count >= selected_patient_num:\n",
    "        break\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f'processing {i}')\n",
    "\n",
    "#     race = race_all[index_shuf[i]]\n",
    "#     male = male_all[index_shuf[i]]\n",
    "#     hisp = hispanic_all[index_shuf[i]]\n",
    "#     glaucoma = glaucoma_all[index_shuf[i]]\n",
    "#     clockhours = clockhours_all[index_shuf[i]]\n",
    "#     md = md_all[index_shuf[i]]\n",
    "#     datadir = datadir_all[index_shuf[i]]\n",
    "#     octpath = octpath_all[index_shuf[i]]\n",
    "#     pid = pid_all[index_shuf[i]]\n",
    "    \n",
    "    pid, race, male, hisp, glaucoma, md, datadir, octpath, datetime_timeoftest, clockhours, age, meta_row = selected_samples[index_shuf[i]]\n",
    "\n",
    "    if not os.path.exists(os.path.join(octpath, datadir, 'slo.jp2')):\n",
    "        continue\n",
    "#     if selected_patient_num > 0 and len(glaucoma_all_new) >= selected_patient_num:\n",
    "#         break\n",
    "\n",
    "#     if pid in pid_all_new:\n",
    "#         continue\n",
    "\n",
    "#     if selected_patient_num < 0 or balanced_num < 0 or np.sum(np.array(race_all_new) == race) < balanced_num:\n",
    "    race_all_new.append(race)\n",
    "    male_all_new.append(male)\n",
    "    hispanic_all_new.append(hisp)\n",
    "    clockhours_all_new.append(clockhours)\n",
    "    glaucoma_all_new.append(glaucoma)\n",
    "    pid_all_new.append(pid)\n",
    "    age_all_new.append(age)\n",
    "\n",
    "    if extract_to_files:\n",
    "        # disc\n",
    "        data_disk = open(os.path.join(octpath, datadir, 'mask_disc.csv'))\n",
    "        img_disk = np.reshape([float(row) for row in data_disk], (200, -1))\n",
    "        # cup\n",
    "        data_cup = open(os.path.join(octpath, datadir, 'mask_cup.csv'))\n",
    "        img_cup = np.reshape([float(row) for row in data_cup], (200, -1))\n",
    "        # ilm\n",
    "        data_ilm2nd = open(os.path.join(octpath, datadir, 'segmentation_ilm_2nd.csv'))\n",
    "        img_ilm2nd = np.reshape([float(row) for row in data_ilm2nd], (200, -1))\n",
    "        data_ilm = open(os.path.join(octpath, datadir, 'segmentation_ilm.csv'))\n",
    "        img_ilm = np.reshape([float(row) for row in data_ilm], (200, -1))\n",
    "        # gcl\n",
    "        data_gcl = open(os.path.join(octpath, datadir, 'segmentation_rnfl_to_gcl.csv'))\n",
    "        img_gcl = np.reshape([float(row) for row in data_gcl], (200, -1))\n",
    "        # rnflt map\n",
    "        rnflt_map = (img_gcl - img_ilm2nd) * 0.00195503 * 1000 # bscanPixelspacingDepth * 1000\n",
    "        rnflt_map[img_disk==1] = -1\n",
    "        rnflt_map[img_cup==1] = -2\n",
    "        img_gcl = img_gcl * 0.00195503 * 1000\n",
    "        img_ilm = np.abs(img_ilm-np.max(img_ilm)) * 0.00195503 * 1000\n",
    "        \n",
    "        fundus = cv2.imread(os.path.join(octpath, datadir, 'slo.jp2'))\n",
    "        fundus = cv2.rotate(fundus, cv2.ROTATE_90_CLOCKWISE)\n",
    "        fundus = fundus / fundus.max() * 255\n",
    "        fundus = fundus.astype(np.uint8)\n",
    "#         fundus = cv2.resize(fundus, (200, 200))\n",
    "#         fig, ax = plt.subplots(nrows=2, ncols=1)\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.imshow(fundus)\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.imshow(rnflt_map)\n",
    "#         sys.exit()\n",
    "\n",
    "        bscans = []\n",
    "        for j in range(1, 201):\n",
    "            bscan = cv2.imread(os.path.join(octpath, datadir, f'bscan{j}.jp2'))\n",
    "            bscan = bscan[:,:,0]\n",
    "            bscan = cv2.rotate(bscan, cv2.ROTATE_90_CLOCKWISE)\n",
    "            bscan = cv2.resize(bscan, (200,200))\n",
    "            # bscan = cv2.resize(cv2.rotate(bscan, cv2.ROTATE_90_CLOCKWISE), (300,200))\n",
    "            bscan = np.flip(bscan, axis=1)\n",
    "            bscan = bscan[None,:,:]\n",
    "            bscans.append(bscan)\n",
    "        bscans = np.vstack(bscans)\n",
    "\n",
    "#         file_name = f\"data_{index_shuf[i]:06d}.npz\"\n",
    "        file_name = f\"data_{count:06d}.npz\"\n",
    "        \n",
    "        tmp_dict = {'file_name': file_name, 'md': md, 'glaucoma_label': glaucoma}\n",
    "        tmp_dict.update(meta_row.to_dict())\n",
    "        meta_all.append(tmp_dict)\n",
    "        \n",
    "#         np.savez(os.path.join(output_folder, f\"data_{index_shuf[i]:06d}.npz\"), \n",
    "        np.savez(os.path.join(output_folder, file_name), \n",
    "                rnflt=rnflt_map,\n",
    "                ilm=img_ilm,\n",
    "                slo_fundus=fundus,\n",
    "                oct_bscans=bscans,\n",
    "                clockhours=clockhours,\n",
    "                md=md,\n",
    "                race=race,\n",
    "                male=male,\n",
    "                hispanic=hisp,\n",
    "                age=age,\n",
    "                glaucoma=glaucoma,\n",
    "                datadir=datadir)\n",
    "                # tds=tds,\n",
    "                # clockhours=clockhours,\n",
    "                # pid=octID,\n",
    "                # datadir=datadir\n",
    "        count += 1\n",
    "\n",
    "dict_meta_all = merge_dicts(meta_all)\n",
    "meta_all_df = pd.DataFrame.from_dict(dict_meta_all)\n",
    "meta_all_df.to_csv(os.path.join(output_folder, 'selected_samples_meta.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "937848c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratios = [0.6, 0.7, 1.]  # Divide the list into training, validation, testing proportions 60%, 10%, and 30%\n",
    "# ratios = [0.6364, 0.7273, 1.] \n",
    "\n",
    "all_samples = find_all_files(output_folder, '*.npz')\n",
    "\n",
    "training_samples, val_samples, testing_samples =  divide_list(all_samples, ratios)\n",
    "# print(f'{len(training_samples)}, {len(val_samples)}, {len(testing_samples)}')\n",
    "# sys.exit()\n",
    "\n",
    "subset_path = os.path.join(output_folder, 'train')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in training_samples:\n",
    "    shutil.move(os.path.join(output_folder, x), os.path.join(subset_path, x))\n",
    "\n",
    "subset_path = os.path.join(output_folder, 'val')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in val_samples:\n",
    "    shutil.move(os.path.join(output_folder, x), os.path.join(subset_path, x))\n",
    "    \n",
    "subset_path = os.path.join(output_folder, 'test')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in testing_samples:\n",
    "    shutil.move(os.path.join(output_folder, x), os.path.join(subset_path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9e97f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divide into training, validation, testing sets with seed 5399\n",
      "8862, 1477, 4432\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "output_folder = f'/data/home/luoy/project/python/datasets/harvard/glaucoma_lancet_journal_3755_-1'\n",
    "\n",
    "ratios = [0.6, 0.7, 1.]  # Divide the list into training, validation, testing proportions 60%, 10%, and 30%\n",
    "# ratios = [0.6364, 0.7273, 1.] \n",
    "\n",
    "sep_seed = -1 # 9648 9220 for iccv Galucoma Fairness dataset # -1\n",
    "if sep_seed < 0:\n",
    "    sep_seed = int(np.random.randint(10000, size=1)[0])\n",
    "set_random_seed(sep_seed)\n",
    "print(f'divide into training, validation, testing sets with seed {sep_seed}')\n",
    "\n",
    "all_samples = find_all_files_(output_folder, '*.npz')\n",
    "\n",
    "random.shuffle(all_samples)\n",
    "\n",
    "training_samples, val_samples, testing_samples =  divide_list(all_samples, ratios)\n",
    "print(f'{len(training_samples)}, {len(val_samples)}, {len(testing_samples)}')\n",
    "\n",
    "subset_path = os.path.join(output_folder, f'{sep_seed}', 'train')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in training_samples:\n",
    "    shutil.copy(os.path.join(output_folder, x), os.path.join(subset_path, x))\n",
    "\n",
    "subset_path = os.path.join(output_folder, f'{sep_seed}', 'val')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in val_samples:\n",
    "    shutil.copy(os.path.join(output_folder, x), os.path.join(subset_path, x))\n",
    "    \n",
    "subset_path = os.path.join(output_folder, f'{sep_seed}', 'test')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in testing_samples:\n",
    "    shutil.copy(os.path.join(output_folder, x), os.path.join(subset_path, x))\n",
    "print(f'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [2100, 300, 900]  # Divide the list into training, validation, testing proportions 60%, 10%, and 30%\n",
    "\n",
    "all_samples = find_all_files(output_folder, '*.npz')\n",
    "\n",
    "training_samples, val_samples, testing_samples =  divide_list(all_samples, ratios)\n",
    "print(f'{len(training_samples)}, {len(val_samples)}, {len(testing_samples)}')\n",
    "\n",
    "subset_path = os.path.join(output_folder, 'train')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in training_samples:\n",
    "    shutil.move(os.path.join(output_folder, x), os.path.join(subset_path, x))\n",
    "\n",
    "subset_path = os.path.join(output_folder, 'val')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in val_samples:\n",
    "    shutil.move(os.path.join(output_folder, x), os.path.join(subset_path, x))\n",
    "    \n",
    "subset_path = os.path.join(output_folder, 'test')\n",
    "if not os.path.exists(subset_path):\n",
    "    os.makedirs(subset_path)\n",
    "for x in testing_samples:\n",
    "    shutil.move(os.path.join(output_folder, x), os.path.join(subset_path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8053375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist duplicate ids: True\n",
      "# of right eyes: 23962, # of left eyes: 21245, total # of eyes: 45207\n"
     ]
    }
   ],
   "source": [
    "# meta_file_path = os.path.join(output_folder, 'selected_samples_meta.csv')\n",
    "meta_file_path = match_table_file\n",
    "dr_meta = pd.read_csv(meta_file_path, sep=',')\n",
    "duplicate_check = dr_meta['id'].duplicated().any()\n",
    "print(f\"exist duplicate ids: {duplicate_check}\")\n",
    "print(f\"# of right eyes: {len(dr_meta[(dr_meta['righteye']==1)])}, # of left eyes: {len(dr_meta[(dr_meta['righteye']==0)])}, total # of eyes: {len(dr_meta)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
